{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eepcrOvdQe10",
        "outputId": "5be542be-a53e-4154-a368-8b0a75912768"
      },
      "id": "eepcrOvdQe10",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading pennylane-0.44.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray==0.8.2 (from pennylane)\n",
            "  Downloading autoray-0.8.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (6.2.4)\n",
            "Collecting pennylane-lightning>=0.44 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.44->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.30.443.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2026.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane-0.44.0-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.8.2-py3-none-any.whl (935 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m935.6/935.6 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.44.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.30.443.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.8.2 diastatic-malt-2.15.2 pennylane-0.44.0 pennylane-lightning-0.44.0 rustworkx-0.17.1 scipy-openblas32-0.3.30.443.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6ee6dd15",
      "metadata": {
        "id": "6ee6dd15"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "import sys\n",
        "\n",
        "# Setting our constants\n",
        "sys.path.append('..')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/aifactory-team/AFCompetition/main/9245/train_X.npy\n",
        "!wget https://raw.githubusercontent.com/aifactory-team/AFCompetition/main/9245/train_y.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWebYxMPP_pK",
        "outputId": "2f24746b-0e7a-4921-dc0e-c97c8a42e12f"
      },
      "id": "mWebYxMPP_pK",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-15 14:43:56--  https://raw.githubusercontent.com/aifactory-team/AFCompetition/main/9245/train_X.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32896 (32K) [application/octet-stream]\n",
            "Saving to: ‘train_X.npy’\n",
            "\n",
            "train_X.npy         100%[===================>]  32.12K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2026-01-15 14:43:56 (3.34 MB/s) - ‘train_X.npy’ saved [32896/32896]\n",
            "\n",
            "--2026-01-15 14:43:56--  https://raw.githubusercontent.com/aifactory-team/AFCompetition/main/9245/train_y.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256 [application/octet-stream]\n",
            "Saving to: ‘train_y.npy’\n",
            "\n",
            "train_y.npy         100%[===================>]     256  --.-KB/s    in 0s      \n",
            "\n",
            "2026-01-15 14:43:56 (5.87 MB/s) - ‘train_y.npy’ saved [256/256]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9e7cb661",
      "metadata": {
        "id": "9e7cb661"
      },
      "outputs": [],
      "source": [
        "train_X = np.load(\"train_X.npy\")\n",
        "train_y = np.load(\"train_y.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pennylane pennylane-lightning pennylane-lightning-gpu --quiet\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9gJQ_0m6Bqtk",
        "outputId": "5725388b-b66a-433a-8833-ea17458b47fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9gJQ_0m6Bqtk",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.3/913.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m581.2/581.2 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7fb7b4ff",
      "metadata": {
        "id": "7fb7b4ff"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pennylane import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# ==========================================\n",
        "# 1. Inference (Model Prediction) - 기존 유지\n",
        "# ==========================================\n",
        "def get_predictions(model, inputs):\n",
        "    \"\"\"Run inference on inputs using the trained model.\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        predicted_labels = torch.argmax(outputs, dim=1)\n",
        "    return predicted_labels.cpu().numpy()\n",
        "\n",
        "def data_to_tensor(X, y):\n",
        "    tensor_X = torch.tensor(X, dtype=torch.complex64)\n",
        "    tensor_y = torch.tensor(y, dtype=torch.long)\n",
        "    return tensor_X, tensor_y\n",
        "\n",
        "t_train_X, t_train_y = data_to_tensor(train_X, train_y)\n",
        "train_dataset = TensorDataset(t_train_X, t_train_y)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e5b0ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08e5b0ae",
        "outputId": "1cc3faf8-8064-40aa-bd47-207da1f1a818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ QNN Model Created!\n",
            "• Device: cpu\n",
            "• Total parameters: 72\n",
            "• Parameter shape: torch.Size([72])\n",
            "Epoch [1/1000] | Loss: 1.4557 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [2/1000] | Loss: 1.4550 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [3/1000] | Loss: 1.4540 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [4/1000] | Loss: 1.4529 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [5/1000] | Loss: 1.4516 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [6/1000] | Loss: 1.4501 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [7/1000] | Loss: 1.4485 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [8/1000] | Loss: 1.4467 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [9/1000] | Loss: 1.4448 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [10/1000] | Loss: 1.4428 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [11/1000] | Loss: 1.4406 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [12/1000] | Loss: 1.4384 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [13/1000] | Loss: 1.4360 | Test Acc: 0.2250 | Best Acc: 0.2250\n",
            "Epoch [14/1000] | Loss: 1.4336 | Test Acc: 0.2250 | Best Acc: 0.2250\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "# ────────────── Quantum Circuit Setup ──────────────\n",
        "\n",
        "n_qubits = 8\n",
        "n_layers = 3\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "def preprocess_to_8d(X):\n",
        "    \"\"\"\n",
        "    X: (N, 256) real-valued\n",
        "    return: (N, 8) normalized\n",
        "    \"\"\"\n",
        "    X = X.reshape(-1, 8, 32).mean(axis=2)  # 256 → 8\n",
        "    X = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
        "    return X\n",
        "\n",
        "\n",
        "def Quantum_classifier(params):\n",
        "    \"\"\"\n",
        "    Trainable part of the quantum circuit:\n",
        "    - Rotations + CNOT chain for all layers except last\n",
        "    - Final layer: only Rotations\n",
        "    \"\"\"\n",
        "    wires = list(range(n_qubits))\n",
        "    params = params.reshape(-1, 3, n_qubits)\n",
        "\n",
        "    # All layers except last: Rot + CNOT\n",
        "    for layer in range(params.shape[0] - 1):\n",
        "        for i, wire in enumerate(wires):\n",
        "            qml.Rot(params[layer, 0, i], params[layer, 1, i], params[layer, 2, i], wires=wire)\n",
        "        for i in range(len(wires) - 1):\n",
        "            qml.CNOT(wires=[wires[i], wires[i+1]])\n",
        "\n",
        "    # Last layer: only Rot\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.Rot(params[-1, 0, i], params[-1, 1, i], params[-1, 2, i], wires=wire)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
        "def linear_2qubit_block(state, params):\n",
        "    \"\"\"\n",
        "    state: (n_qubits,) 단일 샘플\n",
        "    params: (total_params,)\n",
        "    \"\"\"\n",
        "    n_qubits = len(state)           # ✅ batch가 아니면 len(state) 사용\n",
        "    params = params.reshape(n_layers, 3, n_qubits)\n",
        "\n",
        "    # StatePrep 또는 AngleEmbedding\n",
        "    qml.AngleEmbedding(state, wires=range(n_qubits), rotation=\"Y\")\n",
        "\n",
        "    # Quantum classifier\n",
        "    for layer in range(n_layers):\n",
        "        for i in range(n_qubits):\n",
        "            qml.Rot(params[layer,0,i], params[layer,1,i], params[layer,2,i], wires=i)\n",
        "        if layer < n_layers - 1:\n",
        "            for i in range(n_qubits - 1):\n",
        "                qml.CNOT(wires=[i,i+1])\n",
        "\n",
        "    return qml.probs(wires=[6,7])  # 4-class 출력\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ────────────── PyTorch QNN Module ──────────────\n",
        "class QNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.total_params = n_layers*3*n_qubits\n",
        "        self.params = nn.Parameter(torch.randn(self.total_params)*0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, 8)\n",
        "        probs_list = [linear_2qubit_block(x[i], self.params) for i in range(x.shape[0])]\n",
        "        return torch.stack(probs_list)  # shape: (batch_size, 4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ────────────── Model Creation ──────────────\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = QNN().to(device)\n",
        "\n",
        "print(\"✅ QNN Model Created!\")\n",
        "print(f\"• Device: {device}\")\n",
        "print(f\"• Total parameters: {model.total_params}\")\n",
        "print(f\"• Parameter shape: {model.params.shape}\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ────────────── 가상의 데이터 생성 ──────────────\n",
        "# 예: 256-dim 입력, 4-class 분류\n",
        "num_samples = 200\n",
        "x_data = torch.randn(num_samples, 256)\n",
        "y_data = torch.randint(0, 4, (num_samples,))\n",
        "\n",
        "# train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "X_train_8d = preprocess_to_8d(X_train.numpy())\n",
        "X_test_8d = preprocess_to_8d(X_test.numpy())\n",
        "\n",
        "X_train_t = torch.tensor(X_train_8d, dtype=torch.float32).to(device)\n",
        "X_test_t = torch.tensor(X_test_8d, dtype=torch.float32).to(device)\n",
        "y_train_t = y_train.to(device)\n",
        "y_test_t = y_test.to(device)\n",
        "\n",
        "# ────────────── 모델, 옵티마이저, 손실함수 ──────────────\n",
        "model = QNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ────────────── 학습 루프 ──────────────\n",
        "epochs = 1000\n",
        "best_acc = 0.0\n",
        "best_params = None\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train_t)\n",
        "    loss = criterion(outputs, y_train_t)\n",
        "\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient clipping for stability\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    # Accuracy 계산\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = model(X_test_t)  # ✅ 8차원 입력 사용\n",
        "        pred = torch.argmax(probs, dim=1)\n",
        "        acc = (pred == y_test_t).float().mean().item()\n",
        "\n",
        "    # best_acc, best_params 업데이트\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_params = model.params.detach().clone()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f\"Epoch [{epoch}/{epochs}] | Loss: {loss.item():.4f} | Test Acc: {acc:.4f} | Best Acc: {best_acc:.4f}\")\n",
        "\n",
        "# ────────────── 학습 종료 후 출력 ──────────────\n",
        "print(\"\\n✅ Training Finished!\")\n",
        "print(f\"Best Test Accuracy: {best_acc:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3708b410",
      "metadata": {
        "id": "3708b410"
      },
      "outputs": [],
      "source": [
        "# 배치 하나 가져오기\n",
        "batch_X, batch_y = next(iter(train_loader))\n",
        "\n",
        "# 첫 샘플만 사용\n",
        "x0 = batch_X[0].to(device)\n",
        "\n",
        "# 회로 시각화\n",
        "qml.draw_mpl(QNode)(x0, model.params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3108aa99",
      "metadata": {
        "id": "3108aa99"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# 1. Specify measurement qubits\n",
        "measurement = [0, 1]\n",
        "\n",
        "# 2. Extract trained parameters\n",
        "params = model.params.detach().cpu().numpy()\n",
        "\n",
        "# 3. Define circuit for QASM conversion (Ansatz only, no StatePrep or Measurement)\n",
        "@qml.qnode(dev)\n",
        "def QASM_Circuit(params):\n",
        "    # |00000000> 에서 시작 (default)\n",
        "    QuantumAnsatz(params)\n",
        "    return qml.probs(wires=measurement_wires)\n",
        "\n",
        "\n",
        "\n",
        "qasm_str = qml.to_openqasm(\n",
        "    QASM_Circuit,\n",
        "    measure_all=False\n",
        ")(model.params.detach())\n",
        "\n",
        "\n",
        "submission = {\n",
        "    \"qasm\": qasm_str,\n",
        "    \"measurements\": measurement_wires\n",
        "}\n",
        "\n",
        "with open(\"baseline.json\", \"w\") as f:\n",
        "    json.dump(submission, f)\n",
        "\n",
        "print(\"✅ baseline.json 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('baseline.json')"
      ],
      "metadata": {
        "id": "dBuatQ2JTa3c"
      },
      "id": "dBuatQ2JTa3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGRzTHyoTt7u"
      },
      "id": "nGRzTHyoTt7u",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}